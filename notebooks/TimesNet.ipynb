{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_J78vpb1tk-",
        "outputId": "47d0559f-1260-431d-f647-0431ac8c616a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Time-Series-Library (1).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Time-Series-Library')"
      ],
      "metadata": {
        "id": "yyVH_zp6-DEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Time-Series-Library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBkYraIt-QhN",
        "outputId": "0dd0c6d1-d12e-4776-a6cb-b43c13e4a241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Time-Series-Library\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patool\n",
        "!pip install sktime\n",
        "!pip install reformer_pytorch\n",
        "!pip install PyWavelets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs2JwFxo-ZsT",
        "outputId": "73956195-3fdb-4ff0-903f-bae7d4943410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-4.0.1-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Downloading patool-4.0.1-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.5/86.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-4.0.1\n",
            "Collecting sktime\n",
            "  Downloading sktime-0.37.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: joblib<1.5,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from sktime) (1.4.2)\n",
            "Requirement already satisfied: numpy<2.3,>=1.21 in /usr/local/lib/python3.11/dist-packages (from sktime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from sktime) (24.2)\n",
            "Requirement already satisfied: pandas<2.3.0,>=1.1 in /usr/local/lib/python3.11/dist-packages (from sktime) (2.2.2)\n",
            "Collecting scikit-base<0.13.0,>=0.6.1 (from sktime)\n",
            "  Downloading scikit_base-0.12.2-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: scikit-learn<1.7.0,>=0.24 in /usr/local/lib/python3.11/dist-packages (from sktime) (1.6.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from sktime) (1.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7.0,>=0.24->sktime) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=1.1->sktime) (1.17.0)\n",
            "Downloading sktime-0.37.0-py3-none-any.whl (37.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_base-0.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-base, sktime\n",
            "Successfully installed scikit-base-0.12.2 sktime-0.37.0\n",
            "Collecting reformer_pytorch\n",
            "  Downloading reformer_pytorch-1.4.4-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting axial-positional-embedding>=0.1.0 (from reformer_pytorch)\n",
            "  Downloading axial_positional_embedding-0.3.12-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from reformer_pytorch) (0.8.1)\n",
            "Collecting local-attention (from reformer_pytorch)\n",
            "  Downloading local_attention-1.11.1-py3-none-any.whl.metadata (907 bytes)\n",
            "Collecting product-key-memory (from reformer_pytorch)\n",
            "  Downloading product_key_memory-0.2.11-py3-none-any.whl.metadata (717 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from reformer_pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->reformer_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->reformer_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->reformer_pytorch) (1.3.0)\n",
            "Collecting hyper-connections>=0.1.8 (from local-attention->reformer_pytorch)\n",
            "  Downloading hyper_connections-0.1.15-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting colt5-attention>=0.10.14 (from product-key-memory->reformer_pytorch)\n",
            "  Downloading CoLT5_attention-0.11.1-py3-none-any.whl.metadata (737 bytes)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from colt5-attention>=0.10.14->product-key-memory->reformer_pytorch) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->reformer_pytorch) (3.0.2)\n",
            "Downloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n",
            "Downloading axial_positional_embedding-0.3.12-py3-none-any.whl (6.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading local_attention-1.11.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading product_key_memory-0.2.11-py3-none-any.whl (6.5 kB)\n",
            "Downloading CoLT5_attention-0.11.1-py3-none-any.whl (18 kB)\n",
            "Downloading hyper_connections-0.1.15-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyper-connections, axial-positional-embedding, local-attention, colt5-attention, product-key-memory, reformer_pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed axial-positional-embedding-0.3.12 colt5-attention-0.11.1 hyper-connections-0.1.15 local-attention-1.11.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 product-key-memory-0.2.11 reformer_pytorch-1.4.4\n",
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "args = Namespace(\n",
        "    # basic config\n",
        "    task_name='long_term_forecast',\n",
        "    is_training=1,\n",
        "    model_id='test',\n",
        "    model='Autoformer',\n",
        "\n",
        "    # data loader\n",
        "    data='ETTh1',\n",
        "    root_path='./data/ETT/',\n",
        "    data_path='ETTh1.csv',\n",
        "    features='MS',\n",
        "    target='label',\n",
        "    freq='h',\n",
        "    checkpoints='./checkpoints/',\n",
        "\n",
        "    # forecasting task\n",
        "    seq_len=96,\n",
        "    label_len=48,\n",
        "    pred_len=1,\n",
        "    seasonal_patterns='Monthly',\n",
        "    inverse=False,\n",
        "\n",
        "    # imputation task\n",
        "    mask_rate=0.25,\n",
        "\n",
        "    # anomaly detection task\n",
        "    anomaly_ratio=0.25,\n",
        "\n",
        "    # model define\n",
        "    expand=2,\n",
        "    d_conv=4,\n",
        "    top_k=5,\n",
        "    num_kernels=6,\n",
        "    enc_in=16,##\n",
        "    dec_in=16,##\n",
        "    c_out=16,##\n",
        "    d_model=16,\n",
        "    n_heads=8,\n",
        "    e_layers=2,\n",
        "    d_layers=1,\n",
        "    d_ff=256,\n",
        "    moving_avg=25,\n",
        "    factor=3, ##\n",
        "    distil=True,\n",
        "    dropout=0.1,\n",
        "    embed='timeF',\n",
        "    activation='gelu',\n",
        "    channel_independence=1,\n",
        "    decomp_method='moving_avg',\n",
        "    use_norm=1,\n",
        "    down_sampling_layers=0,\n",
        "    down_sampling_window=1,\n",
        "    down_sampling_method=None,\n",
        "    seg_len=96,\n",
        "\n",
        "    # optimization\n",
        "    num_workers=10,\n",
        "    itr=1,\n",
        "    train_epochs=10,\n",
        "    batch_size=32,\n",
        "    patience=3,\n",
        "    learning_rate=0.0001,\n",
        "    des='Exp',##\n",
        "    loss='MSE',\n",
        "    lradj='type1',\n",
        "    use_amp=False,\n",
        "\n",
        "    # GPU\n",
        "    use_gpu=True,\n",
        "    gpu=0,\n",
        "    gpu_type='cuda',\n",
        "    use_multi_gpu=False,\n",
        "    devices='0,1,2,3',\n",
        "\n",
        "    # projector\n",
        "    p_hidden_dims=[128, 128],\n",
        "    p_hidden_layers=2,\n",
        "\n",
        "    # metrics\n",
        "    use_dtw=False,\n",
        "\n",
        "    # augmentation\n",
        "    augmentation_ratio=0,\n",
        "    seed=2,\n",
        "    jitter=False,\n",
        "    scaling=False,\n",
        "    permutation=False,\n",
        "    randompermutation=False,\n",
        "    magwarp=False,\n",
        "    timewarp=False,\n",
        "    windowslice=False,\n",
        "    windowwarp=False,\n",
        "    rotation=False,\n",
        "    spawner=False,\n",
        "    dtwwarp=False,\n",
        "    shapedtwwarp=False,\n",
        "    wdba=False,\n",
        "    discdtw=False,\n",
        "    discsdtw=False,\n",
        "    extra_tag=\"\",\n",
        "\n",
        "    # TimeXer\n",
        "    patch_len=16,\n",
        "    selected_cols = ['open', 'high', 'low', 'close', 'volume', 'MACD',\n",
        "       'MACD_signal', 'MACD_diff', 'RSI', 'Bollinger_High', 'Bollinger_Low',\n",
        "       'Bollinger_Mid', 'EMA_12', 'EMA_26', 'SMA_50', 'SMA_200']\n",
        ")\n",
        "\n",
        "# Now you can use `args` like you would after `parser.parse_args()`\n"
      ],
      "metadata": {
        "id": "-TN4eNhD924b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout"
      ],
      "metadata": {
        "id": "foar5ILtpL2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.is_training:\n",
        "    for ii in range(args.itr):\n",
        "        # setting record of experiments\n",
        "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_expand{}_dc{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
        "            args.task_name,\n",
        "            args.model_id,\n",
        "            args.model,\n",
        "            args.data,\n",
        "            args.features,\n",
        "            args.seq_len,\n",
        "            args.label_len,\n",
        "            args.pred_len,\n",
        "            args.d_model,\n",
        "            args.n_heads,\n",
        "            args.e_layers,\n",
        "            args.d_layers,\n",
        "            args.d_ff,\n",
        "            args.expand,\n",
        "            args.d_conv,\n",
        "            args.factor,\n",
        "            args.embed,\n",
        "            args.distil,\n",
        "            args.des, ii)\n",
        "else:\n",
        "    ii = 0\n",
        "    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_expand{}_dc{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
        "        args.task_name,\n",
        "        args.model_id,\n",
        "        args.model,\n",
        "        args.data,\n",
        "        args.features,\n",
        "        args.seq_len,\n",
        "        args.label_len,\n",
        "        args.pred_len,\n",
        "        args.d_model,\n",
        "        args.n_heads,\n",
        "        args.e_layers,\n",
        "        args.d_layers,\n",
        "        args.d_ff,\n",
        "        args.expand,\n",
        "        args.d_conv,\n",
        "        args.factor,\n",
        "        args.embed,\n",
        "        args.distil,\n",
        "        args.des, ii)"
      ],
      "metadata": {
        "id": "4CryZCjZzpuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_fake = pd.read_pickle('/content/drive/MyDrive/data_fake3.pickle')\n",
        "df_fake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kXnwHlljBpbV",
        "outputId": "c8c37906-27b4-4157-eeba-6dca94226045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            open       high        low      close      volume    return  \\\n",
              "0      19.685892  21.685892  17.685892  20.000000  146.654316  1.518463   \n",
              "1      20.000000  22.000000  18.000000  20.314108  150.395645  1.495750   \n",
              "2      20.314108  22.314108  18.314108  20.627905  152.299767  1.472253   \n",
              "3      20.627905  22.627905  18.627905  20.941083  150.325654  1.448027   \n",
              "4      20.941083  22.941083  18.941083  21.253332  150.593170  1.423126   \n",
              "...          ...        ...        ...        ...         ...       ...   \n",
              "49996  18.435655  20.435655  16.435655  18.746668  149.391456  1.600215   \n",
              "49997  18.746668  20.746668  16.746668  19.058917  148.417509  1.581275   \n",
              "49998  19.058917  21.058917  17.058917  19.372095  152.626683  1.561290   \n",
              "49999  19.372095  21.372095  17.372095  19.685892  151.883846  1.540331   \n",
              "50000  19.685892  21.685892  17.685892  20.000000  154.155670  1.518463   \n",
              "\n",
              "           MACD  MACD_signal  MACD_diff        RSI  ...  Bollinger_Low  \\\n",
              "0      1.697097     1.536909   0.160188  98.977705  ...      13.677476   \n",
              "1      1.729560     1.575440   0.154121  99.061153  ...      13.942994   \n",
              "2      1.760317     1.612415   0.147902  99.136948  ...      14.214464   \n",
              "3      1.789336     1.647799   0.141537  99.205855  ...      14.491618   \n",
              "4      1.816589     1.681557   0.135032  99.268560  ...      14.774183   \n",
              "...         ...          ...        ...        ...  ...            ...   \n",
              "49996  1.550842     1.368025   0.182817  98.548400  ...      12.680053   \n",
              "49997  1.589796     1.412379   0.177417  98.672250  ...      12.919214   \n",
              "49998  1.627181     1.455340   0.171841  98.784285  ...      13.165335   \n",
              "49999  1.662960     1.496864   0.166096  98.885739  ...      13.418171   \n",
              "50000  1.697098     1.536910   0.160187  98.977705  ...      13.677476   \n",
              "\n",
              "       Bollinger_Mid     EMA_12     EMA_26     SMA_50  SMA_200  prev_return  \\\n",
              "0          17.107607  18.331282  16.634185  13.734326     20.0     0.015956   \n",
              "1          17.404354  18.636332  16.906772  13.940509     20.0     0.015705   \n",
              "2          17.703663  18.942728  17.182411  14.152673     20.0     0.015447   \n",
              "3          18.005238  19.250167  17.460831  14.370607     20.0     0.015182   \n",
              "4          18.308781  19.558347  17.741757  14.594096     20.0     0.014911   \n",
              "...              ...        ...        ...        ...      ...          ...   \n",
              "49996      15.952048  17.130534  15.579692  12.973369     20.0     0.016870   \n",
              "49997      16.235650  17.427209  15.837413  13.153659     20.0     0.016656   \n",
              "49998      16.522967  17.726422  16.099241  13.340707     20.0     0.016432   \n",
              "49999      16.813715  18.027879  16.364919  13.534326     20.0     0.016198   \n",
              "50000      17.107607  18.331282  16.634184  13.734326     20.0     0.015956   \n",
              "\n",
              "       label                                               text label2  \n",
              "0          1  Conceptually cream skimming has two basic dime...      1  \n",
              "1          1  yeah i tell you what though if you go price so...      1  \n",
              "2          1  But a few Christian mosaics survive above the ...      1  \n",
              "3          1  It's not that the questions they asked weren't...      1  \n",
              "4          1  Thebes held onto power until the 12th Dynasty,...      1  \n",
              "...      ...                                                ...    ...  \n",
              "49996      1  I think we're going to find some other things....      1  \n",
              "49997      1  Anyway, what causes indifference to politics t...      1  \n",
              "49998      1  it's like a mystery uh theater uh that you you...      1  \n",
              "49999      1  uh the the gas station i didn't know this but ...      1  \n",
              "50000      1  During her lifetime, 69 30 b.c. , the infamous...      1  \n",
              "\n",
              "[50001 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a0e978c-b336-4e04-ab48-bf660bad67cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>return</th>\n",
              "      <th>MACD</th>\n",
              "      <th>MACD_signal</th>\n",
              "      <th>MACD_diff</th>\n",
              "      <th>RSI</th>\n",
              "      <th>...</th>\n",
              "      <th>Bollinger_Low</th>\n",
              "      <th>Bollinger_Mid</th>\n",
              "      <th>EMA_12</th>\n",
              "      <th>EMA_26</th>\n",
              "      <th>SMA_50</th>\n",
              "      <th>SMA_200</th>\n",
              "      <th>prev_return</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>label2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.685892</td>\n",
              "      <td>21.685892</td>\n",
              "      <td>17.685892</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>146.654316</td>\n",
              "      <td>1.518463</td>\n",
              "      <td>1.697097</td>\n",
              "      <td>1.536909</td>\n",
              "      <td>0.160188</td>\n",
              "      <td>98.977705</td>\n",
              "      <td>...</td>\n",
              "      <td>13.677476</td>\n",
              "      <td>17.107607</td>\n",
              "      <td>18.331282</td>\n",
              "      <td>16.634185</td>\n",
              "      <td>13.734326</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.015956</td>\n",
              "      <td>1</td>\n",
              "      <td>Conceptually cream skimming has two basic dime...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>20.314108</td>\n",
              "      <td>150.395645</td>\n",
              "      <td>1.495750</td>\n",
              "      <td>1.729560</td>\n",
              "      <td>1.575440</td>\n",
              "      <td>0.154121</td>\n",
              "      <td>99.061153</td>\n",
              "      <td>...</td>\n",
              "      <td>13.942994</td>\n",
              "      <td>17.404354</td>\n",
              "      <td>18.636332</td>\n",
              "      <td>16.906772</td>\n",
              "      <td>13.940509</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.015705</td>\n",
              "      <td>1</td>\n",
              "      <td>yeah i tell you what though if you go price so...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20.314108</td>\n",
              "      <td>22.314108</td>\n",
              "      <td>18.314108</td>\n",
              "      <td>20.627905</td>\n",
              "      <td>152.299767</td>\n",
              "      <td>1.472253</td>\n",
              "      <td>1.760317</td>\n",
              "      <td>1.612415</td>\n",
              "      <td>0.147902</td>\n",
              "      <td>99.136948</td>\n",
              "      <td>...</td>\n",
              "      <td>14.214464</td>\n",
              "      <td>17.703663</td>\n",
              "      <td>18.942728</td>\n",
              "      <td>17.182411</td>\n",
              "      <td>14.152673</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.015447</td>\n",
              "      <td>1</td>\n",
              "      <td>But a few Christian mosaics survive above the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.627905</td>\n",
              "      <td>22.627905</td>\n",
              "      <td>18.627905</td>\n",
              "      <td>20.941083</td>\n",
              "      <td>150.325654</td>\n",
              "      <td>1.448027</td>\n",
              "      <td>1.789336</td>\n",
              "      <td>1.647799</td>\n",
              "      <td>0.141537</td>\n",
              "      <td>99.205855</td>\n",
              "      <td>...</td>\n",
              "      <td>14.491618</td>\n",
              "      <td>18.005238</td>\n",
              "      <td>19.250167</td>\n",
              "      <td>17.460831</td>\n",
              "      <td>14.370607</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.015182</td>\n",
              "      <td>1</td>\n",
              "      <td>It's not that the questions they asked weren't...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.941083</td>\n",
              "      <td>22.941083</td>\n",
              "      <td>18.941083</td>\n",
              "      <td>21.253332</td>\n",
              "      <td>150.593170</td>\n",
              "      <td>1.423126</td>\n",
              "      <td>1.816589</td>\n",
              "      <td>1.681557</td>\n",
              "      <td>0.135032</td>\n",
              "      <td>99.268560</td>\n",
              "      <td>...</td>\n",
              "      <td>14.774183</td>\n",
              "      <td>18.308781</td>\n",
              "      <td>19.558347</td>\n",
              "      <td>17.741757</td>\n",
              "      <td>14.594096</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.014911</td>\n",
              "      <td>1</td>\n",
              "      <td>Thebes held onto power until the 12th Dynasty,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>18.435655</td>\n",
              "      <td>20.435655</td>\n",
              "      <td>16.435655</td>\n",
              "      <td>18.746668</td>\n",
              "      <td>149.391456</td>\n",
              "      <td>1.600215</td>\n",
              "      <td>1.550842</td>\n",
              "      <td>1.368025</td>\n",
              "      <td>0.182817</td>\n",
              "      <td>98.548400</td>\n",
              "      <td>...</td>\n",
              "      <td>12.680053</td>\n",
              "      <td>15.952048</td>\n",
              "      <td>17.130534</td>\n",
              "      <td>15.579692</td>\n",
              "      <td>12.973369</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.016870</td>\n",
              "      <td>1</td>\n",
              "      <td>I think we're going to find some other things....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>18.746668</td>\n",
              "      <td>20.746668</td>\n",
              "      <td>16.746668</td>\n",
              "      <td>19.058917</td>\n",
              "      <td>148.417509</td>\n",
              "      <td>1.581275</td>\n",
              "      <td>1.589796</td>\n",
              "      <td>1.412379</td>\n",
              "      <td>0.177417</td>\n",
              "      <td>98.672250</td>\n",
              "      <td>...</td>\n",
              "      <td>12.919214</td>\n",
              "      <td>16.235650</td>\n",
              "      <td>17.427209</td>\n",
              "      <td>15.837413</td>\n",
              "      <td>13.153659</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.016656</td>\n",
              "      <td>1</td>\n",
              "      <td>Anyway, what causes indifference to politics t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>19.058917</td>\n",
              "      <td>21.058917</td>\n",
              "      <td>17.058917</td>\n",
              "      <td>19.372095</td>\n",
              "      <td>152.626683</td>\n",
              "      <td>1.561290</td>\n",
              "      <td>1.627181</td>\n",
              "      <td>1.455340</td>\n",
              "      <td>0.171841</td>\n",
              "      <td>98.784285</td>\n",
              "      <td>...</td>\n",
              "      <td>13.165335</td>\n",
              "      <td>16.522967</td>\n",
              "      <td>17.726422</td>\n",
              "      <td>16.099241</td>\n",
              "      <td>13.340707</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.016432</td>\n",
              "      <td>1</td>\n",
              "      <td>it's like a mystery uh theater uh that you you...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>19.372095</td>\n",
              "      <td>21.372095</td>\n",
              "      <td>17.372095</td>\n",
              "      <td>19.685892</td>\n",
              "      <td>151.883846</td>\n",
              "      <td>1.540331</td>\n",
              "      <td>1.662960</td>\n",
              "      <td>1.496864</td>\n",
              "      <td>0.166096</td>\n",
              "      <td>98.885739</td>\n",
              "      <td>...</td>\n",
              "      <td>13.418171</td>\n",
              "      <td>16.813715</td>\n",
              "      <td>18.027879</td>\n",
              "      <td>16.364919</td>\n",
              "      <td>13.534326</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.016198</td>\n",
              "      <td>1</td>\n",
              "      <td>uh the the gas station i didn't know this but ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50000</th>\n",
              "      <td>19.685892</td>\n",
              "      <td>21.685892</td>\n",
              "      <td>17.685892</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>154.155670</td>\n",
              "      <td>1.518463</td>\n",
              "      <td>1.697098</td>\n",
              "      <td>1.536910</td>\n",
              "      <td>0.160187</td>\n",
              "      <td>98.977705</td>\n",
              "      <td>...</td>\n",
              "      <td>13.677476</td>\n",
              "      <td>17.107607</td>\n",
              "      <td>18.331282</td>\n",
              "      <td>16.634184</td>\n",
              "      <td>13.734326</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.015956</td>\n",
              "      <td>1</td>\n",
              "      <td>During her lifetime, 69 30 b.c. , the infamous...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50001 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a0e978c-b336-4e04-ab48-bf660bad67cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a0e978c-b336-4e04-ab48-bf660bad67cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a0e978c-b336-4e04-ab48-bf660bad67cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6155ab0-4dde-49e0-94a3-021aca70c4a3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6155ab0-4dde-49e0-94a3-021aca70c4a3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6155ab0-4dde-49e0-94a3-021aca70c4a3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_546307e9-5d79-4ce5-b96a-d7aa0f6500e3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_fake')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_546307e9-5d79-4ce5-b96a-d7aa0f6500e3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_fake');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_fake"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake['open'] = 0\n",
        "df_fake['high'] = 0\n",
        "df_fake['low'] = 0\n",
        "df_fake['close'] = 0\n",
        "df_fake['volume'] = 0"
      ],
      "metadata": {
        "id": "ukR4go7gtAGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from utils.timefeatures import time_features\n",
        "from data_provider.m4 import M4Dataset, M4Meta\n",
        "from data_provider.uea import subsample, interpolate_missing, Normalizer\n",
        "from sktime.datasets import load_from_tsfile_to_dataframe\n",
        "import warnings\n",
        "from utils.augmentation import run_augmentation_single\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "cNDErZ9YBgbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_cols = ['open', 'high', 'low', 'close', 'volume', 'MACD',\n",
        "       'MACD_signal', 'MACD_diff', 'RSI', 'Bollinger_High', 'Bollinger_Low',\n",
        "       'Bollinger_Mid', 'EMA_12', 'EMA_26', 'SMA_50', 'SMA_200']"
      ],
      "metadata": {
        "id": "YlGhLYmoB6gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def generate_timestamps(start_time, end_time, timeframe_minutes):\n",
        "    start = pd.to_datetime(start_time)\n",
        "    end = pd.to_datetime(end_time)\n",
        "    timestamps = pd.date_range(start=start, end=end, freq=f'{timeframe_minutes}min')\n",
        "    return [ts.strftime('%Y-%m-%d %H:%M:%S') for ts in timestamps]\n",
        "\n",
        "# Example usage\n",
        "start_time = '2024-01-23 09:30:00'\n",
        "end_time = '2025-05-01 23:30:00'\n",
        "timeframe_minutes = 5\n",
        "\n",
        "timestamps = generate_timestamps(start_time, end_time, timeframe_minutes)\n",
        "\n",
        "len(timestamps)\n",
        "\n",
        "df_fake['date'] = timestamps[-len(df_fake):]\n",
        "\n",
        "df_raw = df_fake[['date']+selected_cols+['return']]"
      ],
      "metadata": {
        "id": "3oWbf8ILByz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_ETT_hour(Dataset):\n",
        "    def __init__(self, args, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        self.args = args\n",
        "        target = self.args.target\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.selected_cols = self.args.selected_cols\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "\n",
        "        df_raw = df_fake[['date']+selected_cols+['return']].copy()\n",
        "        df_raw = df_fake.copy()\n",
        "\n",
        "        len_train = (0, int(0.7 * len(df_raw)))\n",
        "        len_val = (int(0.7 * len(df_raw))-self.seq_len, int(0.85 * len(df_raw)))\n",
        "        len_test = (int(0.85 * len(df_raw))-self.seq_len, len(df_raw))\n",
        "        len_split_data = {0: len_train, 1: len_val, 2: len_test}\n",
        "        # border1s = [0, 12 * 30 * 24 - seq_len, 12 * 30 * 24 + 4 * 30 * 24 - seq_len]\n",
        "        # border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = len_split_data[self.set_type][0]\n",
        "        border2 = len_split_data[self.set_type][1]\n",
        "\n",
        "\n",
        "        df_data = df_raw[self.selected_cols]\n",
        "        df_target = df_raw[[self.target]]\n",
        "\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1:border2]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "\n",
        "        if self.scale:\n",
        "            scaler = StandardScaler()\n",
        "            train_data_y = df_target[border1:border2]\n",
        "            scaler.fit(train_data_y.values)\n",
        "            data_target = scaler.transform(df_target.values)\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], axis=1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "\n",
        "        if self.set_type == 0 and self.args.augmentation_ratio > 0:\n",
        "            self.data_x, self.data_y, augmentation_tags = run_augmentation_single(self.data_x, self.data_y, self.args)\n",
        "\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)"
      ],
      "metadata": {
        "id": "ir_1nSWJCnkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "flag = 'train'#, 'test', 'val'\n",
        "timeenc = 0 if args.embed != 'timeF' else 1\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "def create_dataset(flag):\n",
        "  shuffle_flag = False if (flag == 'test' or flag == 'TEST') else True\n",
        "  drop_last = False\n",
        "  data_set = Dataset_ETT_hour(\n",
        "      args = args,\n",
        "      root_path=args.root_path,\n",
        "      data_path=args.data_path,\n",
        "      flag=flag,\n",
        "      size=[args.seq_len, args.label_len, args.pred_len],\n",
        "      features=args.features,\n",
        "      target=args.target,\n",
        "      timeenc=timeenc,\n",
        "      freq=args.freq,\n",
        "      seasonal_patterns=args.seasonal_patterns)\n",
        "\n",
        "  data_loader = DataLoader(\n",
        "      data_set,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle_flag,\n",
        "      num_workers=args.num_workers,\n",
        "      drop_last=drop_last)\n",
        "\n",
        "  return data_set, data_loader"
      ],
      "metadata": {
        "id": "SsUnHG9MJ9nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data_provider.data_factory import data_provider\n",
        "from exp.exp_basic import Exp_Basic\n",
        "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
        "from utils.metrics import metric\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "from utils.dtw_metric import dtw, accelerated_dtw\n",
        "from utils.augmentation import run_augmentation, run_augmentation_single\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "_1VQA5ZMOp9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.fft\n",
        "from layers.Embed import DataEmbedding\n",
        "from layers.Conv_Blocks import Inception_Block_V1\n",
        "\n",
        "\n",
        "def FFT_for_Period(x, k=2):\n",
        "    # [B, T, C]\n",
        "    xf = torch.fft.rfft(x, dim=1)\n",
        "    # find period by amplitudes\n",
        "    frequency_list = abs(xf).mean(0).mean(-1)\n",
        "    frequency_list[0] = 0\n",
        "    _, top_list = torch.topk(frequency_list, k)\n",
        "    top_list = top_list.detach().cpu().numpy()\n",
        "    period = x.shape[1] // top_list\n",
        "    return period, abs(xf).mean(-1)[:, top_list]\n",
        "\n",
        "\n",
        "class TimesBlock(nn.Module):\n",
        "    def __init__(self, configs):\n",
        "        super(TimesBlock, self).__init__()\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.k = configs.top_k\n",
        "        # parameter-efficient design\n",
        "        self.conv = nn.Sequential(\n",
        "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
        "                               num_kernels=configs.num_kernels),\n",
        "            nn.GELU(),\n",
        "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
        "                               num_kernels=configs.num_kernels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, N = x.size()\n",
        "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
        "\n",
        "        res = []\n",
        "        for i in range(self.k):\n",
        "            period = period_list[i]\n",
        "            # padding\n",
        "            if (self.seq_len + self.pred_len) % period != 0:\n",
        "                length = (\n",
        "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
        "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
        "                out = torch.cat([x, padding], dim=1)\n",
        "            else:\n",
        "                length = (self.seq_len + self.pred_len)\n",
        "                out = x\n",
        "            # reshape\n",
        "            out = out.reshape(B, length // period, period,\n",
        "                              N).permute(0, 3, 1, 2).contiguous()\n",
        "            # 2D conv: from 1d Variation to 2d Variation\n",
        "            out = self.conv(out)\n",
        "            # reshape back\n",
        "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
        "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
        "        res = torch.stack(res, dim=-1)\n",
        "        # adaptive aggregation\n",
        "        period_weight = F.softmax(period_weight, dim=1)\n",
        "        period_weight = period_weight.unsqueeze(\n",
        "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
        "        res = torch.sum(res * period_weight, -1)\n",
        "        # residual connection\n",
        "        res = res + x\n",
        "        return res\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, configs):\n",
        "        super(Model, self).__init__()\n",
        "        self.configs = configs\n",
        "        self.task_name = configs.task_name\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.label_len = configs.label_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.model = nn.ModuleList([TimesBlock(configs)\n",
        "                                    for _ in range(configs.e_layers)])\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        self.layer = configs.e_layers\n",
        "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
        "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
        "            self.predict_linear = nn.Linear(\n",
        "                self.seq_len, self.pred_len + self.seq_len)\n",
        "            self.projection = nn.Linear(\n",
        "                configs.d_model, configs.c_out, bias=True)\n",
        "        if self.task_name == 'classification':\n",
        "            self.act = F.gelu\n",
        "            self.dropout = nn.Dropout(configs.dropout)\n",
        "            self.projection = nn.Linear(\n",
        "                configs.d_model * configs.seq_len, configs.num_class)\n",
        "\n",
        "    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
        "        # Normalization from Non-stationary Transformer\n",
        "        means = x_enc.mean(1, keepdim=True).detach()\n",
        "        x_enc = x_enc - means\n",
        "        stdev = torch.sqrt(\n",
        "            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
        "        x_enc /= stdev\n",
        "\n",
        "        # embedding\n",
        "        # enc_out2 = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
        "        enc_out = self.predict_linear(enc_out.permute(0, 2, 1)).permute(\n",
        "            0, 2, 1)  # align temporal dimension\n",
        "        # TimesNet\n",
        "        for i in range(self.layer):\n",
        "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
        "        # porject back\n",
        "        dec_out = self.projection(enc_out)\n",
        "        # De-Normalization from Non-stationary Transformer\n",
        "        dec_out = dec_out * \\\n",
        "                  (stdev[:, 0, :].unsqueeze(1).repeat(\n",
        "                      1, self.pred_len + self.seq_len, 1))\n",
        "        dec_out = dec_out + \\\n",
        "                  (means[:, 0, :].unsqueeze(1).repeat(\n",
        "                      1, self.pred_len + self.seq_len, 1))\n",
        "\n",
        "        return dec_out\n",
        "\n",
        "\n",
        "    def classification(self, x_enc, x_mark_enc):\n",
        "        # embedding\n",
        "        enc_out = self.enc_embedding(x_enc, None)  # [B,T,C]\n",
        "        # TimesNet\n",
        "        for i in range(self.layer):\n",
        "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
        "\n",
        "        # Output\n",
        "        # the output transformer encoder/decoder embeddings don't include non-linearity\n",
        "        output = self.act(enc_out)\n",
        "        output = self.dropout(output)\n",
        "        # zero-out padding embeddings\n",
        "        output = output * x_mark_enc.unsqueeze(-1)\n",
        "        # (batch_size, seq_length * d_model)\n",
        "        output = output.reshape(output.shape[0], -1)\n",
        "        output = self.projection(output)  # (batch_size, num_classes)\n",
        "        return output\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
        "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
        "            dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
        "            # return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
        "            return dec_out\n",
        "        if self.task_name == 'imputation':\n",
        "            dec_out = self.imputation(\n",
        "                x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\n",
        "            return dec_out  # [B, L, D]\n",
        "        if self.task_name == 'anomaly_detection':\n",
        "            dec_out = self.anomaly_detection(x_enc)\n",
        "            return dec_out  # [B, L, D]\n",
        "        if self.task_name == 'classification':\n",
        "            dec_out = self.classification(x_enc, x_mark_enc)\n",
        "            return dec_out  # [B, N]\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "aD1Maxrgw-Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.enc_in=16\n",
        "args.d_model=512\n",
        "args.c_out=16"
      ],
      "metadata": {
        "id": "8KpATFqSh5iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from models import Autoformer, Transformer, TimesNet\n",
        "\n",
        "# model = TimesNet.Model(args).float()\n",
        "model = Model(args).float()\n",
        "\n",
        "if args.use_multi_gpu and args.use_gpu:\n",
        "    model = nn.DataParallel(model, device_ids=args.device_ids)\n",
        "model = model.to(device)\n",
        "\n",
        "model_optim = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train_data, train_loader = create_dataset(flag='train')\n",
        "vali_data, vali_loader = create_dataset(flag='val')\n",
        "test_data, test_loader = create_dataset(flag='test')\n"
      ],
      "metadata": {
        "id": "_FeYhqZbQah4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = os.path.join(args.checkpoints, setting)\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "time_now = time.time()\n",
        "\n",
        "train_steps = len(train_loader)\n",
        "early_stopping = EarlyStopping(patience=args.patience, verbose=True)\n",
        "\n",
        "\n",
        "if args.use_amp:\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# for epoch in range(args.train_epochs):\n",
        "iter_count = 0\n",
        "train_loss = []\n",
        "\n",
        "model.train()\n",
        "epoch_time = time.time()\n",
        "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
        "    print(batch_x.shape)\n",
        "    # decoder input\n",
        "    batch_x = batch_x.float().to(device)\n",
        "    batch_y = batch_y.float().to(device)\n",
        "    batch_x_mark = batch_x_mark.float().to(device)\n",
        "    batch_y_mark = batch_y_mark.float().to(device)\n",
        "    dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
        "    dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
        "    f_dim = -1\n",
        "    # encoder - decoder\n",
        "        # encoder - decoder\n",
        "    if args.use_amp:\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "            f_dim = -1 if args.features == 'MS' else 0\n",
        "            outputs2 = outputs[:, -args.pred_len:, f_dim:]\n",
        "\n",
        "    else:\n",
        "        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "        f_dim = -1 if args.features == 'MS' else 0\n",
        "        outputs2 = outputs[:, -args.pred_len:, f_dim:]\n",
        "\n",
        "\n",
        "    print(outputs.shape, outputs2.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNI0J44QOVW7",
        "outputId": "fba7712a-c76c-42ec-dd70-36147105572d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 96, 16])\n",
            "torch.Size([32, 97, 16]) torch.Size([32, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.use_amp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHZsCdklUvAz",
        "outputId": "3368e7d3-f3a7-49e1-9716-818311aa8b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if args.use_amp:\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(args.train_epochs):\n",
        "    iter_count = 0\n",
        "    train_loss = []\n",
        "\n",
        "    model.train()\n",
        "    epoch_time = time.time()\n",
        "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
        "        iter_count += 1\n",
        "        model_optim.zero_grad()\n",
        "        batch_x = batch_x.float().to(device)\n",
        "        batch_y = batch_y.float().to(device)\n",
        "        batch_x_mark = batch_x_mark.float().to(device)\n",
        "        batch_y_mark = batch_y_mark.float().to(device)\n",
        "\n",
        "        # decoder input\n",
        "        dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
        "        dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
        "\n",
        "        # encoder - decoder\n",
        "        if args.use_amp:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                f_dim = -1 if args.features == 'MS' else 0\n",
        "                outputs = outputs[:, -args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                train_loss.append(loss.item())\n",
        "        else:\n",
        "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "            f_dim = -1 if args.features == 'MS' else 0\n",
        "            outputs = outputs[:, -args.pred_len:, f_dim:]\n",
        "            batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
        "            speed = (time.time() - time_now) / iter_count\n",
        "            left_time = speed * ((args.train_epochs - epoch) * train_steps - i)\n",
        "            print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
        "            iter_count = 0\n",
        "            time_now = time.time()\n",
        "\n",
        "        if args.use_amp:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(model_optim)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            model_optim.step()\n",
        "\n",
        "    print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
        "    train_loss = np.average(train_loss)\n",
        "\n",
        "\n",
        "    print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
        "        epoch + 1, train_steps, train_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "XiCnSUhkUPkc",
        "outputId": "4865fe31-8458-4a4e-aadb-78f47811c2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\titers: 100, epoch: 1 | loss: 0.0000002\n",
            "\tspeed: 0.7308s/iter; left time: 7900.5729s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-608cd723b98c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0miter_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_x_mark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x_mark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.task_name = 'classification'\n",
        "args.num_class = 3"
      ],
      "metadata": {
        "id": "vrP1Cbh9Za5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from models import Autoformer, Transformer, TimesNet\n",
        "\n",
        "model = TimesNet.Model(args).float()\n",
        "if args.use_multi_gpu and args.use_gpu:\n",
        "    model = nn.DataParallel(model, device_ids=args.device_ids)\n",
        "model = model.to(device)\n",
        "\n",
        "model_optim = optim.RAdam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_data, train_loader = create_dataset(flag='train')\n",
        "vali_data, vali_loader = create_dataset(flag='val')\n",
        "test_data, test_loader = create_dataset(flag='test')\n"
      ],
      "metadata": {
        "id": "tXDJ4iruW2wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7tZHZ-0HXZOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.join(args.checkpoints, setting)\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "time_now = time.time()\n",
        "\n",
        "train_steps = len(train_loader)\n",
        "early_stopping = EarlyStopping(patience=args.patience, verbose=True)\n",
        "\n",
        "\n",
        "for epoch in range(args.train_epochs):\n",
        "    iter_count = 0\n",
        "    train_loss = []\n",
        "\n",
        "    model.train()\n",
        "    epoch_time = time.time()\n",
        "\n",
        "    for i, (batch_x, label, padding_mask) in enumerate(train_loader):\n",
        "        iter_count += 1\n",
        "        model_optim.zero_grad()\n",
        "\n",
        "        batch_x = batch_x.float().to(device)\n",
        "        padding_mask = padding_mask.float().to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        outputs = model(batch_x, padding_mask, None, None)\n",
        "        loss = criterion(outputs, label.long().squeeze(-1))\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
        "            speed = (time.time() - time_now) / iter_count\n",
        "            left_time = speed * ((args.train_epochs - epoch) * train_steps - i)\n",
        "            print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
        "            iter_count = 0\n",
        "            time_now = time.time()\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=4.0)\n",
        "        model_optim.step()\n",
        "\n",
        "    print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
        "    train_loss = np.average(train_loss)\n",
        "    # vali_loss, val_accuracy = self.vali(vali_data, vali_loader, criterion)\n",
        "    # test_loss, test_accuracy = self.vali(test_data, test_loader, criterion)\n",
        "\n",
        "    print(\n",
        "        \"Epoch: {0}, Steps: {1} | Train Loss: {2:.3f} Vali Loss: {3:.3f} Vali Acc: {4:.3f} Test Loss: {5:.3f} Test Acc: {6:.3f}\"\n",
        "        .format(epoch + 1, train_steps, train_loss))\n",
        "    # early_stopping(-val_accuracy, model, path)\n",
        "    # if early_stopping.early_stop:\n",
        "    #     print(\"Early stopping\")\n",
        "    #     break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8HHi6DWZZZuX",
        "outputId": "aae82ecf-39fa-439b-9267-92325a833cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-72bba49bb251>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepoch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0miter_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.enc_in = train_data.feature_df.shape[1]\n",
        "args.num_class = 3"
      ],
      "metadata": {
        "id": "QZk7kuYqXjhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}